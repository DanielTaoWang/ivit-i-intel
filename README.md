# iNIT-I
iNIT-I is a ai inference solution on various device.

## Feature
1. Good performance: optimization with NVIDIA, Intel device.
2. Easy to build: provide the docker image to use.
3. Easy to use: simplify the `TensorRT`, `OpenVINO` api. 
4. Multiple Usage we provide the CLI API and WEB API, user could choose what they want.
5. Provide demo site at [init-i-demo](https://github.com/InnoIPA/init-i-demo)
6. Provide the sample model in [ai-model-zoo](https://github.com/InnoIPA/ai-model-zoo)

## How to use
|   Title   |   Content |
|   ---     |   ---     |
|   Intel User      |   [README-NV.md](./README-NV.md)
|   NVIDIA User     |   [README-INTEL.md](./README-INTEL.md)
|   Xilinx User     |   -
|   WEB API User    |   [README-WEB.md](./README-WEB.md)

## Future
- [x] Integration with Web API
- [ ] Framework: Integrate Xilinx
- [ ] Framework: Integrate Hailo
